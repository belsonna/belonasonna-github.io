![Profile photo](profiles.jpg){:style="width:600px;"}
## About Me

I am a PhD student in the [Humanizing Machine Intelligence ](https://hmi.anu.edu.au/) group at the Australian National University, where my research focuses on the formal verification of AI ethics principles in automated decision-making processes. I am fortunate to be supervised by [Dr. Alban Grastien](https://comp.anu.edu.au/people/alban-grastien/), [Prof. Lexing Xie](https://users.cecs.anu.edu.au/~xlx/index.html), and [Dr. Michael Norrish](https://researchportalplus.anu.edu.au/en/persons/michael-norrish). My work aims to design assessment frameworks based on formal abductive explanations to audit **proxy-discrimination, unfairness, and privacy leakage** in AI decisions. I am particularly interested in applying these methods to healthcare systems, where trustworthy AI is critical for real-world impact.

Previously I was Associate AI Engineer at [Future](https://www.future.co.jp/en/) where I worked on erly sign detection of dementia with eye gaze detection with Deep Learning Models in Tokyo. I was also research intern at the [Montreal AI Ethics Institute](https://montrealethics.ai/) where I worked on the social impact of AI.I was part of the first cohort of the [African Master’s of Machine Intelligence](https://aimsammi.org/) in Rwanda. Before that, I completed a Master in Computer Science from the Universite of Ngaoundere.

Outside of reserach, I am an advocate for promoting the study of AI and STEM by underrepresented communities, especially in Africa. I am Founder and co-lead of [Bel’s AI Initiative](https://www.linkedin.com/company/bel-s-ai-initiative/) which conducts outreach about AI in Central Africa with a focus on rural areas. I am part of [AfroLeadership](https://afroleadership.org/), the [WIMLDS Yaounde](http://wimlds.org/about-the-yaounde-team-2/) chapter, and co-organiser of KMERAI events.

---

## Research Interests

- **Fairness in AI** – auditing decision processes and mitigating structural bias  
- **Abductive reasoning** – generating formal explanations beyond counterfactual methods  
- **Explainable AI (XAI)** – making models transparent and accountable  

---

## Publications

- **Sonna, B.** (2024). *Explaining Why: A Formal Abductive Framework for Workplace-Driven Mental Health Decisions in Tech Environments*. _IJCAI Workshop_.  
- **Sonna, B.** (2023). *Formal Abductive Explanations for Navigating Mental Health Help-Seeking and Diversity in Tech Workplaces*. _NeurIPS Workshop_.  
- [Google Scholar Profile](https://scholar.google.com/) _(update with your link)_  

---

## Projects

- **Fairness Auditing Toolkit** – A framework for detecting proxy discrimination using formal abductive explanations.  
- **Workplace Mental Health AI Study** – Identifying structural features that justify why employees seek treatment.  
- **Ethics in AI Regulation** – Exploring how AI mirrors societal injustice and what human moral transformation is needed.

---

## Contact

- **Email:** your.email@anu.edu.au  
- **LinkedIn:** [linkedin.com/in/belona-sonna](https://www.linkedin.com/in/belona-sonna/)  
- **GitHub:** [github.com/your-username](https://github.com/your-username)

---

*This site is built with [GitHub Pages](https://pages.github.com/) using the Cayman theme.*
