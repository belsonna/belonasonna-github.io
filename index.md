![Profile photo](profiles.jpg){:style="width:600px;"}
## About Me

I am a PhD student in the [Humanizing Machine Intelligence](https://hmi.anu.edu.au/) group at the **Australian National University**, where my research focuses on the **formal verification of AI ethics principles in AI decision processes**. I am honoured to be supervised by [Dr. Alban Grastien](https://comp.anu.edu.au/people/alban-grastien/), [Prof. Lexing Xie](https://users.cecs.anu.edu.au/~xlx/index.html), and [Dr. Michael Norrish](https://researchportalplus.anu.edu.au/en/persons/michael-norrish).

My work aims to design **assessment frameworks based on formal abductive explanations** to audit **proxy discrimination**, **unfairness**, and **privacy leakage** in AI decisions. I am particularly interested in applying these methods to **healthcare systems**, where ensuring trustworthy AI is critical for real-world impact.

Previously, I worked as an **Associate AI Engineer at [Future](https://www.future.co.jp/en/)** in Tokyo, developing deep learning models for **early dementia detection using eye-gaze analysis**. I also served as a **Research Intern at the [Montreal AI Ethics Institute](https://montrealethics.ai/)**, where I examined the **social impacts of AI**. I was part of the first cohort of the [African Master’s in Machine Intelligence](https://aimsammi.org/) program in Rwanda. I hold a **Master’s in Computer Science from the Université de Ngaoundéré**.

Outside of research, I advocate for **expanding access to AI and STEM education** among underrepresented communities, especially in Africa. I am the **Founder and Co-lead of [Bel’s AI Initiative](https://www.linkedin.com/company/bel-s-ai-initiative/)**, which conducts bilingual (English and French) AI outreach in Central Africa with a focus on rural areas. I am also a member of [AfroLeadership](https://afroleadership.org/), the [WIMLDS Yaoundé](http://wimlds.org/about-the-yaounde-team-2/) chapter, and serve as a **co-organizer of [KMERAI Events](https://sites.google.com/view/kmerai-2021/home?authuser=0) events**.

---

## Research Interests

- **Fairness in AI** – auditing decision processes and mitigating structural bias  
- **Abductive reasoning** – generating formal explanations beyond counterfactual methods  
- **Explainable AI (XAI)** – making models transparent and accountable  

---

## Publications

- **Sonna, B.** (2024). *Explaining Why: A Formal Abductive Framework for Workplace-Driven Mental Health Decisions in Tech Environments*. _IJCAI Workshop_.  
- **Sonna, B.** (2023). *Formal Abductive Explanations for Navigating Mental Health Help-Seeking and Diversity in Tech Workplaces*. _NeurIPS Workshop_.  
- [Google Scholar Profile](https://scholar.google.com/) _(update with your link)_  

---

## Projects

- **Fairness Auditing Toolkit** – A framework for detecting proxy discrimination using formal abductive explanations.  
- **Workplace Mental Health AI Study** – Identifying structural features that justify why employees seek treatment.  
- **Ethics in AI Regulation** – Exploring how AI mirrors societal injustice and what human moral transformation is needed.

---

## Contact

- **Email:** your.email@anu.edu.au  
- **LinkedIn:** [linkedin.com/in/belona-sonna](https://www.linkedin.com/in/belona-sonna/)  
- **GitHub:** [github.com/your-username](https://github.com/your-username)

---

*This site is built with [GitHub Pages](https://pages.github.com/) using the Cayman theme.*
